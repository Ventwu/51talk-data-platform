# éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†51Talkæ•°æ®ä¸­å°é¡¹ç›®çš„éƒ¨ç½²æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [æœ¬åœ°å¼€å‘éƒ¨ç½²](#æœ¬åœ°å¼€å‘éƒ¨ç½²)
- [Dockeréƒ¨ç½²](#dockeréƒ¨ç½²)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
- [äº‘å¹³å°éƒ¨ç½²](#äº‘å¹³å°éƒ¨ç½²)
- [ç›‘æ§å’Œæ—¥å¿—](#ç›‘æ§å’Œæ—¥å¿—)
- [å¤‡ä»½å’Œæ¢å¤](#å¤‡ä»½å’Œæ¢å¤)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

## ğŸ› ï¸ ç¯å¢ƒè¦æ±‚

### æœ€ä½ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|----------|----------|
| CPU | 2æ ¸ | 4æ ¸+ |
| å†…å­˜ | 4GB | 8GB+ |
| å­˜å‚¨ | 20GB | 100GB+ SSD |
| ç½‘ç»œ | 100Mbps | 1Gbps |

### è½¯ä»¶ä¾èµ–

#### å¿…éœ€è½¯ä»¶

- **Node.js**: >= 18.0.0
- **MySQL**: >= 8.0
- **Redis**: >= 6.0 (å¯é€‰ï¼Œç”¨äºç¼“å­˜)
- **Nginx**: >= 1.18 (ç”Ÿäº§ç¯å¢ƒ)
- **Docker**: >= 20.10 (Dockeréƒ¨ç½²)
- **Docker Compose**: >= 2.0

#### å¼€å‘å·¥å…·

- **Git**: >= 2.30
- **npm**: >= 8.0 æˆ– **yarn**: >= 1.22
- **PM2**: >= 5.0 (ç”Ÿäº§ç¯å¢ƒè¿›ç¨‹ç®¡ç†)

### æ“ä½œç³»ç»Ÿæ”¯æŒ

- **Linux**: Ubuntu 20.04+, CentOS 8+, RHEL 8+
- **macOS**: 10.15+
- **Windows**: 10/11 (å¼€å‘ç¯å¢ƒ)

## ğŸ  æœ¬åœ°å¼€å‘éƒ¨ç½²

### 1. ç¯å¢ƒå‡†å¤‡

#### å®‰è£…Node.js

```bash
# ä½¿ç”¨nvmå®‰è£…Node.js
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
source ~/.bashrc
nvm install 18
nvm use 18
```

#### å®‰è£…MySQL

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install mysql-server
sudo mysql_secure_installation

# CentOS/RHEL
sudo yum install mysql-server
sudo systemctl start mysqld
sudo systemctl enable mysqld

# macOS (ä½¿ç”¨Homebrew)
brew install mysql
brew services start mysql
```

#### å®‰è£…Redis (å¯é€‰)

```bash
# Ubuntu/Debian
sudo apt install redis-server
sudo systemctl start redis
sudo systemctl enable redis

# CentOS/RHEL
sudo yum install redis
sudo systemctl start redis
sudo systemctl enable redis

# macOS
brew install redis
brew services start redis
```

### 2. é¡¹ç›®è®¾ç½®

#### å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/51talk/data-platform.git
cd data-platform
```

#### å®‰è£…ä¾èµ–

```bash
# å®‰è£…æ ¹ç›®å½•ä¾èµ–
npm install

# å®‰è£…åç«¯ä¾èµ–
cd backend
npm install

# å®‰è£…å‰ç«¯ä¾èµ–
cd ../frontend
npm install

# è¿”å›æ ¹ç›®å½•
cd ..
```

### 3. æ•°æ®åº“é…ç½®

#### åˆ›å»ºæ•°æ®åº“

```sql
-- è¿æ¥MySQL
mysql -u root -p

-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE data_platform CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- åˆ›å»ºç”¨æˆ·
CREATE USER 'data_platform'@'localhost' IDENTIFIED BY 'your_password';
GRANT ALL PRIVILEGES ON data_platform.* TO 'data_platform'@'localhost';
FLUSH PRIVILEGES;
```

#### é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env
```

#### åç«¯ç¯å¢ƒå˜é‡ (backend/.env)

```env
# æœåŠ¡é…ç½®
NODE_ENV=development
PORT=3000
HOST=localhost

# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_PORT=3306
DB_NAME=data_platform
DB_USER=data_platform
DB_PASSWORD=your_password

# Redisé…ç½® (å¯é€‰)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# JWTé…ç½®
JWT_SECRET=your_jwt_secret_key_here
JWT_EXPIRES_IN=24h
JWT_REFRESH_EXPIRES_IN=7d

# æ–‡ä»¶ä¸Šä¼ 
UPLOAD_MAX_SIZE=10485760
UPLOAD_PATH=./uploads

# é‚®ä»¶é…ç½® (å¯é€‰)
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=your_email@example.com
SMTP_PASS=your_email_password

# æ—¥å¿—é…ç½®
LOG_LEVEL=debug
LOG_FILE=./logs/app.log
```

#### å‰ç«¯ç¯å¢ƒå˜é‡ (frontend/.env)

```env
# APIé…ç½®
VITE_API_BASE_URL=http://localhost:3000/api
VITE_APP_NAME=51Talkæ•°æ®ä¸­å°
VITE_APP_VERSION=1.0.0

# å¼€å‘é…ç½®
VITE_DEV_PORT=5173
VITE_DEV_HOST=localhost

# åŠŸèƒ½å¼€å…³
VITE_ENABLE_MOCK=false
VITE_ENABLE_DEBUG=true
```

### 4. æ•°æ®åº“åˆå§‹åŒ–

```bash
# è¿è¡Œæ•°æ®åº“è¿ç§»
cd backend
npm run db:migrate

# æ£€æŸ¥è¿ç§»çŠ¶æ€
npm run db:status
```

### 5. å¯åŠ¨æœåŠ¡

#### å¯åŠ¨åç«¯æœåŠ¡

```bash
cd backend
npm run dev
```

#### å¯åŠ¨å‰ç«¯æœåŠ¡

```bash
# æ–°å¼€ç»ˆç«¯çª—å£
cd frontend
npm run dev
```

### 6. éªŒè¯éƒ¨ç½²

- **å‰ç«¯**: http://localhost:5173
- **åç«¯API**: http://localhost:3000/api
- **å¥åº·æ£€æŸ¥**: http://localhost:3000/api/health

## ğŸ³ Dockeréƒ¨ç½²

### 1. å¿«é€Ÿå¯åŠ¨

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/51talk/data-platform.git
cd data-platform

# å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶
cp .env.example .env

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

### 2. ç¯å¢ƒé…ç½®

#### ä¸»ç¯å¢ƒå˜é‡æ–‡ä»¶ (.env)

```env
# æ•°æ®åº“é…ç½®
MYSQL_ROOT_PASSWORD=root_password_here
MYSQL_DATABASE=data_platform
MYSQL_USER=data_platform
MYSQL_PASSWORD=user_password_here

# Redisé…ç½®
REDIS_PASSWORD=redis_password_here

# åº”ç”¨é…ç½®
JWT_SECRET=your_jwt_secret_key_here
API_PORT=3000
WEB_PORT=80

# ç½‘ç»œé…ç½®
DOMAIN=localhost
SSL_ENABLED=false
```

### 3. æœåŠ¡ç®¡ç†

```bash
# å¯åŠ¨æœåŠ¡
docker-compose up -d

# åœæ­¢æœåŠ¡
docker-compose down

# é‡å¯æœåŠ¡
docker-compose restart

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f backend
docker-compose logs -f frontend

# è¿›å…¥å®¹å™¨
docker-compose exec backend bash
docker-compose exec mysql mysql -u root -p

# æ›´æ–°æœåŠ¡
docker-compose pull
docker-compose up -d
```

### 4. æ•°æ®æŒä¹…åŒ–

```yaml
# docker-compose.yml ä¸­çš„å·é…ç½®
volumes:
  mysql_data:
    driver: local
  redis_data:
    driver: local
  uploads:
    driver: local
```

### 5. ç½‘ç»œé…ç½®

```yaml
# è‡ªå®šä¹‰ç½‘ç»œ
networks:
  data_platform:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

## ğŸš€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 1. æœåŠ¡å™¨å‡†å¤‡

#### ç³»ç»Ÿé…ç½®

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…å¿…è¦è½¯ä»¶
sudo apt install -y curl wget git unzip

# é…ç½®é˜²ç«å¢™
sudo ufw allow 22
sudo ufw allow 80
sudo ufw allow 443
sudo ufw enable

# ä¼˜åŒ–ç³»ç»Ÿå‚æ•°
echo 'vm.max_map_count=262144' | sudo tee -a /etc/sysctl.conf
echo 'fs.file-max=65536' | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

#### åˆ›å»ºåº”ç”¨ç”¨æˆ·

```bash
# åˆ›å»ºåº”ç”¨ç”¨æˆ·
sudo useradd -m -s /bin/bash dataplatform
sudo usermod -aG docker dataplatform

# åˆ‡æ¢åˆ°åº”ç”¨ç”¨æˆ·
sudo su - dataplatform
```

### 2. ä½¿ç”¨Docker Composeéƒ¨ç½²

#### ç”Ÿäº§ç¯å¢ƒé…ç½®æ–‡ä»¶

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - backend
      - frontend
    restart: unless-stopped
    networks:
      - data_platform

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    environment:
      - NODE_ENV=production
      - DB_HOST=mysql
      - REDIS_HOST=redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs/backend:/app/logs
    depends_on:
      - mysql
      - redis
    restart: unless-stopped
    networks:
      - data_platform

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
    restart: unless-stopped
    networks:
      - data_platform

  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./database/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
      - ./database/init.sql:/docker-entrypoint-initdb.d/02-init.sql
      - ./mysql/my.cnf:/etc/mysql/conf.d/my.cnf
    restart: unless-stopped
    networks:
      - data_platform

  redis:
    image: redis:alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - data_platform

volumes:
  mysql_data:
  redis_data:

networks:
  data_platform:
    driver: bridge
```

#### Nginxé…ç½®

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # æ€§èƒ½ä¼˜åŒ–
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 10M;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream backend {
        server backend:3000;
        keepalive 32;
    }

    upstream frontend {
        server frontend:80;
        keepalive 32;
    }

    # HTTPé‡å®šå‘åˆ°HTTPS
    server {
        listen 80;
        server_name your-domain.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPSæœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name your-domain.com;

        # SSLé…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_session_timeout 1d;
        ssl_session_cache shared:SSL:50m;
        ssl_session_tickets off;

        # ç°ä»£SSLé…ç½®
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;
        ssl_prefer_server_ciphers off;

        # HSTS
        add_header Strict-Transport-Security "max-age=63072000" always;

        # å‰ç«¯é™æ€æ–‡ä»¶
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # ç¼“å­˜é™æ€èµ„æº
            location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
            }
        }

        # APIä»£ç†
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocketæ”¯æŒ
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

### 3. SSLè¯ä¹¦é…ç½®

#### ä½¿ç”¨Let's Encrypt

```bash
# å®‰è£…Certbot
sudo apt install certbot python3-certbot-nginx

# è·å–è¯ä¹¦
sudo certbot --nginx -d your-domain.com

# è‡ªåŠ¨ç»­æœŸ
sudo crontab -e
# æ·»åŠ ä»¥ä¸‹è¡Œ
0 12 * * * /usr/bin/certbot renew --quiet
```

#### æ‰‹åŠ¨è¯ä¹¦é…ç½®

```bash
# åˆ›å»ºSSLç›®å½•
mkdir -p nginx/ssl

# å¤åˆ¶è¯ä¹¦æ–‡ä»¶
cp your-cert.pem nginx/ssl/cert.pem
cp your-key.pem nginx/ssl/key.pem

# è®¾ç½®æƒé™
chmod 600 nginx/ssl/key.pem
chmod 644 nginx/ssl/cert.pem
```

### 4. éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh

set -e

echo "å¼€å§‹éƒ¨ç½²æ•°æ®ä¸­å°..."

# æ£€æŸ¥ç¯å¢ƒ
if [ ! -f ".env" ]; then
    echo "é”™è¯¯: .env æ–‡ä»¶ä¸å­˜åœ¨"
    exit 1
fi

# å¤‡ä»½æ•°æ®åº“
echo "å¤‡ä»½æ•°æ®åº“..."
docker-compose exec -T mysql mysqldump -u root -p$MYSQL_ROOT_PASSWORD $MYSQL_DATABASE > backup_$(date +%Y%m%d_%H%M%S).sql

# æ‹‰å–æœ€æ–°ä»£ç 
echo "æ‹‰å–æœ€æ–°ä»£ç ..."
git pull origin main

# æ„å»ºé•œåƒ
echo "æ„å»ºDockeré•œåƒ..."
docker-compose -f docker-compose.prod.yml build --no-cache

# åœæ­¢æ—§æœåŠ¡
echo "åœæ­¢æ—§æœåŠ¡..."
docker-compose -f docker-compose.prod.yml down

# å¯åŠ¨æ–°æœåŠ¡
echo "å¯åŠ¨æ–°æœåŠ¡..."
docker-compose -f docker-compose.prod.yml up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# å¥åº·æ£€æŸ¥
echo "æ‰§è¡Œå¥åº·æ£€æŸ¥..."
if curl -f http://localhost/health; then
    echo "éƒ¨ç½²æˆåŠŸ!"
else
    echo "éƒ¨ç½²å¤±è´¥ï¼Œå›æ»š..."
    docker-compose -f docker-compose.prod.yml down
    # è¿™é‡Œå¯ä»¥æ·»åŠ å›æ»šé€»è¾‘
    exit 1
fi

# æ¸…ç†æ—§é•œåƒ
echo "æ¸…ç†æ—§é•œåƒ..."
docker image prune -f

echo "éƒ¨ç½²å®Œæˆ!"
```

### 5. è¿›ç¨‹ç®¡ç†

#### ä½¿ç”¨PM2 (éDockeréƒ¨ç½²)

```bash
# å®‰è£…PM2
npm install -g pm2

# PM2é…ç½®æ–‡ä»¶
# ecosystem.config.js
module.exports = {
  apps: [{
    name: 'data-platform-backend',
    script: './dist/server.js',
    cwd: './backend',
    instances: 'max',
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'production',
      PORT: 3000
    },
    error_file: './logs/err.log',
    out_file: './logs/out.log',
    log_file: './logs/combined.log',
    time: true,
    max_memory_restart: '1G',
    node_args: '--max-old-space-size=1024'
  }]
};

# å¯åŠ¨åº”ç”¨
pm2 start ecosystem.config.js

# æŸ¥çœ‹çŠ¶æ€
pm2 status

# æŸ¥çœ‹æ—¥å¿—
pm2 logs

# é‡å¯åº”ç”¨
pm2 restart all

# åœæ­¢åº”ç”¨
pm2 stop all

# è®¾ç½®å¼€æœºè‡ªå¯
pm2 startup
pm2 save
```

## â˜ï¸ äº‘å¹³å°éƒ¨ç½²

### 1. AWSéƒ¨ç½²

#### ä½¿ç”¨ECS

```yaml
# aws-task-definition.json
{
  "family": "data-platform",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "1024",
  "memory": "2048",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "containerDefinitions": [
    {
      "name": "backend",
      "image": "your-account.dkr.ecr.region.amazonaws.com/data-platform-backend:latest",
      "portMappings": [
        {
          "containerPort": 3000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "NODE_ENV",
          "value": "production"
        }
      ],
      "secrets": [
        {
          "name": "DB_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:db-password"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/data-platform",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

#### ä½¿ç”¨RDSå’ŒElastiCache

```bash
# åˆ›å»ºRDSå®ä¾‹
aws rds create-db-instance \
    --db-instance-identifier data-platform-db \
    --db-instance-class db.t3.micro \
    --engine mysql \
    --master-username admin \
    --master-user-password your-password \
    --allocated-storage 20 \
    --vpc-security-group-ids sg-xxxxxxxx

# åˆ›å»ºElastiCacheé›†ç¾¤
aws elasticache create-cache-cluster \
    --cache-cluster-id data-platform-redis \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --num-cache-nodes 1
```

### 2. é˜¿é‡Œäº‘éƒ¨ç½²

#### ä½¿ç”¨å®¹å™¨æœåŠ¡ACK

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-platform-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: data-platform-backend
  template:
    metadata:
      labels:
        app: data-platform-backend
    spec:
      containers:
      - name: backend
        image: registry.cn-hangzhou.aliyuncs.com/your-namespace/data-platform-backend:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DB_HOST
          value: "your-rds-endpoint"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: data-platform-backend-service
spec:
  selector:
    app: data-platform-backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer
```

### 3. è…¾è®¯äº‘éƒ¨ç½²

#### ä½¿ç”¨äº‘å‡½æ•°SCF

```javascript
// serverless.yml
service: data-platform

provider:
  name: tencent
  runtime: Nodejs14.18
  region: ap-guangzhou
  memorySize: 512
  timeout: 30

functions:
  api:
    handler: index.handler
    events:
      - apigw:
          path: /{proxy+}
          method: ANY
    environment:
      NODE_ENV: production
      DB_HOST: ${env:DB_HOST}
      DB_PASSWORD: ${env:DB_PASSWORD}

package:
  exclude:
    - node_modules/**
    - .git/**
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### 1. åº”ç”¨ç›‘æ§

#### Prometheus + Grafana

```yaml
# monitoring/docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources

  node-exporter:
    image: prom/node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

volumes:
  prometheus_data:
  grafana_data:
```

#### Prometheusé…ç½®

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'data-platform-backend'
    static_configs:
      - targets: ['backend:3000']
    metrics_path: '/api/metrics'
    scrape_interval: 30s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

### 2. æ—¥å¿—ç®¡ç†

#### ELK Stack

```yaml
# logging/docker-compose.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:7.15.0
    ports:
      - "5044:5044"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/config:/usr/share/logstash/config
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.15.0
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ../logs:/logs:ro
    depends_on:
      - logstash

volumes:
  elasticsearch_data:
```

### 3. å¥åº·æ£€æŸ¥

```bash
#!/bin/bash
# scripts/health-check.sh

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_service() {
    local service_name=$1
    local url=$2
    local expected_status=$3
    
    echo "æ£€æŸ¥ $service_name..."
    
    status=$(curl -s -o /dev/null -w "%{http_code}" $url)
    
    if [ "$status" = "$expected_status" ]; then
        echo "âœ… $service_name æ­£å¸¸"
        return 0
    else
        echo "âŒ $service_name å¼‚å¸¸ (çŠ¶æ€ç : $status)"
        return 1
    fi
}

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
check_database() {
    echo "æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
    
    if docker-compose exec -T mysql mysql -u root -p$MYSQL_ROOT_PASSWORD -e "SELECT 1" > /dev/null 2>&1; then
        echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
        return 0
    else
        echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
        return 1
    fi
}

# æ£€æŸ¥Redisè¿æ¥
check_redis() {
    echo "æ£€æŸ¥Redisè¿æ¥..."
    
    if docker-compose exec -T redis redis-cli ping | grep -q PONG; then
        echo "âœ… Redisè¿æ¥æ­£å¸¸"
        return 0
    else
        echo "âŒ Redisè¿æ¥å¤±è´¥"
        return 1
    fi
}

# æ‰§è¡Œæ£€æŸ¥
echo "å¼€å§‹å¥åº·æ£€æŸ¥..."
echo "=================="

failed=0

check_service "å‰ç«¯æœåŠ¡" "http://localhost" "200" || failed=1
check_service "åç«¯API" "http://localhost/api/health" "200" || failed=1
check_database || failed=1
check_redis || failed=1

echo "=================="

if [ $failed -eq 0 ]; then
    echo "âœ… æ‰€æœ‰æœåŠ¡æ­£å¸¸"
    exit 0
else
    echo "âŒ éƒ¨åˆ†æœåŠ¡å¼‚å¸¸"
    exit 1
fi
```

## ğŸ’¾ å¤‡ä»½å’Œæ¢å¤

### 1. æ•°æ®åº“å¤‡ä»½

```bash
#!/bin/bash
# scripts/backup-database.sh

BACKUP_DIR="./backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/database_backup_$DATE.sql"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
echo "å¼€å§‹å¤‡ä»½æ•°æ®åº“..."
docker-compose exec -T mysql mysqldump \
    -u root \
    -p$MYSQL_ROOT_PASSWORD \
    --single-transaction \
    --routines \
    --triggers \
    $MYSQL_DATABASE > $BACKUP_FILE

if [ $? -eq 0 ]; then
    echo "æ•°æ®åº“å¤‡ä»½æˆåŠŸ: $BACKUP_FILE"
    
    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip $BACKUP_FILE
    echo "å¤‡ä»½æ–‡ä»¶å·²å‹ç¼©: $BACKUP_FILE.gz"
    
    # åˆ é™¤7å¤©å‰çš„å¤‡ä»½
    find $BACKUP_DIR -name "database_backup_*.sql.gz" -mtime +7 -delete
    echo "å·²æ¸…ç†7å¤©å‰çš„å¤‡ä»½æ–‡ä»¶"
else
    echo "æ•°æ®åº“å¤‡ä»½å¤±è´¥"
    exit 1
fi
```

### 2. æ–‡ä»¶å¤‡ä»½

```bash
#!/bin/bash
# scripts/backup-files.sh

BACKUP_DIR="./backups"
DATE=$(date +%Y%m%d_%H%M%S)
FILE_BACKUP="$BACKUP_DIR/files_backup_$DATE.tar.gz"

# å¤‡ä»½ä¸Šä¼ æ–‡ä»¶å’Œé…ç½®
echo "å¼€å§‹å¤‡ä»½æ–‡ä»¶..."
tar -czf $FILE_BACKUP \
    uploads/ \
    .env \
    nginx/ \
    --exclude='*.log'

if [ $? -eq 0 ]; then
    echo "æ–‡ä»¶å¤‡ä»½æˆåŠŸ: $FILE_BACKUP"
else
    echo "æ–‡ä»¶å¤‡ä»½å¤±è´¥"
    exit 1
fi
```

### 3. è‡ªåŠ¨å¤‡ä»½

```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹å¤‡ä»½æ•°æ®åº“
0 2 * * * /path/to/data-platform/scripts/backup-database.sh

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹å¤‡ä»½æ–‡ä»¶
0 3 * * 0 /path/to/data-platform/scripts/backup-files.sh
```

### 4. æ•°æ®æ¢å¤

```bash
#!/bin/bash
# scripts/restore-database.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <backup_file>"
    exit 1
fi

if [ ! -f "$BACKUP_FILE" ]; then
    echo "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $BACKUP_FILE"
    exit 1
fi

echo "è­¦å‘Š: æ­¤æ“ä½œå°†è¦†ç›–å½“å‰æ•°æ®åº“!"
read -p "ç¡®è®¤ç»§ç»­? (y/N): " confirm

if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
    echo "æ“ä½œå·²å–æ¶ˆ"
    exit 0
fi

echo "å¼€å§‹æ¢å¤æ•°æ®åº“..."

# å¦‚æœæ˜¯å‹ç¼©æ–‡ä»¶ï¼Œå…ˆè§£å‹
if [[ $BACKUP_FILE == *.gz ]]; then
    gunzip -c $BACKUP_FILE | docker-compose exec -T mysql mysql -u root -p$MYSQL_ROOT_PASSWORD $MYSQL_DATABASE
else
    docker-compose exec -T mysql mysql -u root -p$MYSQL_ROOT_PASSWORD $MYSQL_DATABASE < $BACKUP_FILE
fi

if [ $? -eq 0 ]; then
    echo "æ•°æ®åº“æ¢å¤æˆåŠŸ"
else
    echo "æ•°æ®åº“æ¢å¤å¤±è´¥"
    exit 1
fi
```

## ğŸ”§ æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜

#### æœåŠ¡æ— æ³•å¯åŠ¨

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tlnp | grep :3000
sudo netstat -tlnp | grep :80

# æ£€æŸ¥DockeræœåŠ¡
sudo systemctl status docker
sudo systemctl start docker

# æ£€æŸ¥å®¹å™¨æ—¥å¿—
docker-compose logs backend
docker-compose logs frontend
docker-compose logs mysql

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker-compose ps
docker stats
```

#### æ•°æ®åº“è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥MySQLå®¹å™¨
docker-compose exec mysql mysql -u root -p

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec backend ping mysql

# æ£€æŸ¥ç¯å¢ƒå˜é‡
docker-compose exec backend env | grep DB_

# æŸ¥çœ‹MySQLæ—¥å¿—
docker-compose logs mysql
```

#### å‰ç«¯æ— æ³•è®¿é—®åç«¯

```bash
# æ£€æŸ¥APIé…ç½®
cat frontend/.env | grep VITE_API_BASE_URL

# æµ‹è¯•APIè¿æ¥
curl http://localhost:3000/api/health

# æ£€æŸ¥Nginxé…ç½®
nginx -t
docker-compose exec nginx nginx -t
```

### 2. æ€§èƒ½é—®é¢˜

#### æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

```sql
-- æŸ¥çœ‹æ…¢æŸ¥è¯¢
SHOW VARIABLES LIKE 'slow_query_log';
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2;

-- æŸ¥çœ‹è¿›ç¨‹åˆ—è¡¨
SHOW PROCESSLIST;

-- åˆ†ææŸ¥è¯¢
EXPLAIN SELECT * FROM users WHERE email = 'test@example.com';

-- æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SHOW INDEX FROM users;
```

#### åº”ç”¨æ€§èƒ½ç›‘æ§

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats

# æŸ¥çœ‹ç³»ç»Ÿè´Ÿè½½
top
htop
iostat -x 1

# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
free -h

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
df -h
du -sh /var/lib/docker
```

### 3. æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
docker-compose logs -f --tail=100 backend

# æŸ¥çœ‹Nginxè®¿é—®æ—¥å¿—
tail -f logs/nginx/access.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/nginx/error.log
grep "ERROR" logs/backend/app.log

# åˆ†ææ—¥å¿—æ¨¡å¼
awk '{print $1}' logs/nginx/access.log | sort | uniq -c | sort -nr
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. æ•°æ®åº“ä¼˜åŒ–

```sql
-- ä¼˜åŒ–MySQLé…ç½®
-- my.cnf
[mysqld]
innodb_buffer_pool_size = 1G
innodb_log_file_size = 256M
innodb_flush_log_at_trx_commit = 2
query_cache_size = 128M
max_connections = 200
tmp_table_size = 64M
max_heap_table_size = 64M

-- æ·»åŠ å¿…è¦ç´¢å¼•
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_dashboards_created_by ON dashboards(created_by);
CREATE INDEX idx_charts_dashboard_id ON charts(dashboard_id);
CREATE INDEX idx_operation_logs_created_at ON operation_logs(created_at);
```

### 2. åº”ç”¨ä¼˜åŒ–

```javascript
// å¯ç”¨å‹ç¼©
const compression = require('compression');
app.use(compression());

// å¯ç”¨ç¼“å­˜
const redis = require('redis');
const client = redis.createClient();

// æ•°æ®åº“è¿æ¥æ± 
const mysql = require('mysql2/promise');
const pool = mysql.createPool({
  host: process.env.DB_HOST,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_NAME,
  waitForConnections: true,
  connectionLimit: 10,
  queueLimit: 0
});
```

### 3. å‰ç«¯ä¼˜åŒ–

```javascript
// vite.config.js
export default defineConfig({
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['react', 'react-dom'],
          antd: ['antd'],
          charts: ['echarts']
        }
      }
    },
    chunkSizeWarningLimit: 1000
  },
  server: {
    proxy: {
      '/api': {
        target: 'http://localhost:3000',
        changeOrigin: true
      }
    }
  }
});
```

### 4. CDNé…ç½®

```nginx
# é™æ€èµ„æºCDN
location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {
    expires 1y;
    add_header Cache-Control "public, immutable";
    add_header Access-Control-Allow-Origin "*";
    
    # å¦‚æœä½¿ç”¨CDN
    # return 301 https://cdn.example.com$request_uri;
}
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰éƒ¨ç½²é—®é¢˜ï¼Œè¯·è”ç³»ï¼š

- **é‚®ç®±**: ops@51talk.com
- **æ–‡æ¡£**: https://docs.51talk-data.com/deployment
- **GitHub Issues**: https://github.com/51talk/data-platform/issues

---

**ç‰ˆæœ¬**: v1.0.0  
**æ›´æ–°æ—¶é—´**: 2024-01-15